{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3505fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "# from brainflow.data_filter import DataFilter, FilterTypes, DetrendOperations, WindowOperations\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176a201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        window, labels = sample['window'], sample['labels']\n",
    "        return {'window': torch.tensor(window.values).to(torch.float32), \n",
    "                'labels': torch.tensor(labels).to(torch.float32)}#.values)}\n",
    "\n",
    "class AbsoluteValue(object):\n",
    "    def __call__(self, sample):\n",
    "        window, labels = sample['window'], sample['labels']\n",
    "        return {'window': torch.abs(window), \n",
    "                'labels': labels}\n",
    "\n",
    "class MinNormalize(object):\n",
    "    def __call__(self, sample):\n",
    "        window, labels = sample['window'], sample['labels']\n",
    "        for channel in range(len(window)):\n",
    "            #print(len(window))\n",
    "            min = torch.min(window[channel])\n",
    "            window[channel] = window[channel] - min\n",
    "            window[channel] = window[channel] / torch.max(window[channel])\n",
    "            window[channel] = torch.nan_to_num(window[channel])\n",
    "        return {'window': (window.unsqueeze(0)), \n",
    "                'labels': labels}\n",
    "\n",
    "# class FixLabels(object):\n",
    "#     def __call__(self, sample):\n",
    "#         window, labels = sample['window'], sample['labels']\n",
    "#         if labels[0] == 2:\n",
    "#             labels = labels - 1\n",
    "#         return {'window': window, \n",
    "#                 'labels': labels}\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.csv_file = pd.read_csv(csv_file, delimiter='\\t', header=None)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # if idx >= len(self.csv_file) / 625:\n",
    "        #     return\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        sample_size = 625\n",
    "        \n",
    "        # window = self.csv_file.iloc[idx*625:idx*625+625, 1:17].transpose()\n",
    "        window = self.csv_file.iloc[idx*sample_size:idx*sample_size+sample_size, 1:17]\n",
    "        labels = [self.csv_file.iloc[idx*sample_size, 32]]#:idx*625+625, 32] # remove brackets for timestep prediction\n",
    "        sample = {'window': window, 'labels': labels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f50ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 625, 16])\n",
      "Full max: tensor(1.)\n",
      "Full min: tensor(0.)\n",
      "288 96 96\n",
      "144 144\n",
      "47 49\n",
      "49 47\n",
      "{'window': tensor([[[1.0000, 0.8881, 0.1018,  ..., 0.7791, 0.0499, 0.0000],\n",
      "         [1.0000, 0.8880, 0.1014,  ..., 0.7807, 0.0495, 0.0000],\n",
      "         [1.0000, 0.8880, 0.1028,  ..., 0.7785, 0.0499, 0.0000],\n",
      "         ...,\n",
      "         [1.0000, 0.8881, 0.0985,  ..., 0.7829, 0.0487, 0.0000],\n",
      "         [1.0000, 0.8874, 0.1052,  ..., 0.7775, 0.0488, 0.0000],\n",
      "         [1.0000, 0.8881, 0.0987,  ..., 0.7832, 0.0488, 0.0000]]]), 'labels': tensor([1.])}\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = EEGDataset(csv_file='./redBlueFull.csv', transform=transforms.Compose([ToTensor(),\n",
    "                                                                                  AbsoluteValue(),\n",
    "                                                                                  MinNormalize()]))\n",
    "\n",
    "# eeg_dataset = EEGDataset(csv_file='./fullData.csv', transform=transforms.Compose([ToTensor(),\n",
    "#                                                                                   AbsoluteValue()]))\n",
    "\n",
    "#eeg_dataset = EEGDataset(csv_file='./fullData.csv', transform=transforms.Compose([ToTensor()]))\n",
    "\n",
    "eeg_dataset = torch.utils.data.Subset(eeg_dataset, range(0, 480))\n",
    "\n",
    "\n",
    "# kuba_dataset = EEGDataset(csv_file='./redBlueFull.csv', transform=transforms.Compose([ToTensor(),\n",
    "#                                                                                   AbsoluteValue(),\n",
    "#                                                                                   MinNormalize()]))\n",
    "\n",
    "# kuba_dataset = torch.utils.data.Subset(kuba_dataset, range(0, 480))\n",
    "\n",
    "# kuba_loader = torch.utils.data.DataLoader(kuba_dataset, batch_size=48,\n",
    "#                                             shuffle=True, num_workers=1)\n",
    "\n",
    "# for x in eeg_dataset:\n",
    "#     print(x[\"labels\"])\n",
    "\n",
    "print(eeg_dataset[0]['window'].shape)\n",
    "\n",
    "#print(eeg_dataset[0]['window'][0][1])\n",
    "\n",
    "# for channel in range(len(eeg_dataset[0]['window'][0])):\n",
    "#     print(torch.min(eeg_dataset[0]['window'][0][channel]))\n",
    "\n",
    "print(\"Full max:\", torch.max(eeg_dataset[0]['window'][0]))\n",
    "print(\"Full min:\", torch.min(eeg_dataset[0]['window'][0]))\n",
    "\n",
    "torch.manual_seed(50) # 80\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(eeg_dataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "\n",
    "zerocount = 0\n",
    "onecount = 0\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    if train_dataset[i]['labels'][0] == 1:\n",
    "        onecount += 1\n",
    "    else:\n",
    "        zerocount += 1\n",
    "\n",
    "print(onecount, zerocount)\n",
    "\n",
    "zerocount = 0\n",
    "onecount = 0\n",
    "\n",
    "for i in range(len(val_dataset)):\n",
    "    if val_dataset[i]['labels'][0] == 1:\n",
    "        onecount += 1\n",
    "    else:\n",
    "        zerocount += 1\n",
    "\n",
    "print(onecount, zerocount)\n",
    "\n",
    "zerocount = 0\n",
    "onecount = 0\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    if test_dataset[i]['labels'][0] == 1:\n",
    "        onecount += 1\n",
    "    else:\n",
    "        zerocount += 1\n",
    "\n",
    "print(onecount, zerocount)\n",
    "\n",
    "print(train_dataset[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc428c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 625, 16])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0]['window'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bca979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_dataset)\n",
    "# window_tensors = torch.empty(size=(num_train, 1, 16, 625))\n",
    "# label_tensors = torch.empty(size=(num_train, 1))\n",
    "\n",
    "# for i in range(num_train):\n",
    "#     window_tensors[i] = train_dataset[i]['window']\n",
    "#     label_tensors[i] = train_dataset[i]['labels']\n",
    "\n",
    "# torch.save(window_tensors, 'window_tensors.pt')\n",
    "# torch.save(label_tensors, 'label_tensors.pt')\n",
    "\n",
    "# window_tensors = torch.load('window_tensors.pt')\n",
    "# label_tensors = torch.load('label_tensors.pt')\n",
    "\n",
    "# print(window_tensors.shape)\n",
    "# print(label_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd116314",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val = len(val_dataset)\n",
    "# val_window_tensors = torch.empty(size=(num_val, 1, 16, 625))\n",
    "# val_label_tensors = torch.empty(size=(num_val, 1))\n",
    "\n",
    "# for i in range(num_val):\n",
    "#     val_window_tensors[i] = val_dataset[i]['window']\n",
    "#     val_label_tensors[i] = val_dataset[i]['labels']\n",
    "\n",
    "# torch.save(val_window_tensors, 'val_window_tensors.pt')\n",
    "# torch.save(val_label_tensors, 'val_label_tensors.pt')\n",
    "\n",
    "# val_window_tensors = torch.load('val_window_tensors.pt')\n",
    "# val_label_tensors = torch.load('val_label_tensors.pt')\n",
    "\n",
    "# print(val_window_tensors.shape)\n",
    "# print(val_label_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3fb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 625\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 16), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        self.fc1 = nn.Linear(4*2*39, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        #x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        #x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        #x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        \n",
    "        # FC Layer\n",
    "        x = x.reshape(-1, 4*2*39)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "    \n",
    "    # def forward(self, x):\n",
    "    #     # Layer 1\n",
    "    #     print(x.shape)\n",
    "    #     x = F.elu(self.conv1(x))\n",
    "    #     print(x.shape)\n",
    "    #     x = self.batchnorm1(x)\n",
    "    #     x = F.dropout(x, 0.25)\n",
    "    #     x = x.permute(0, 3, 1, 2)\n",
    "    #     print(x.shape)\n",
    "        \n",
    "    #     # Layer 2\n",
    "    #     x = self.padding1(x)\n",
    "    #     print(x.shape)\n",
    "    #     x = F.elu(self.conv2(x))\n",
    "    #     print(x.shape)\n",
    "    #     x = self.batchnorm2(x)\n",
    "    #     x = F.dropout(x, 0.25)\n",
    "    #     x = self.pooling2(x)\n",
    "    #     print(x.shape)\n",
    "        \n",
    "    #     # Layer 3\n",
    "    #     x = self.padding2(x)\n",
    "    #     print(x.shape)\n",
    "    #     x = F.elu(self.conv3(x))\n",
    "    #     print(x.shape)\n",
    "    #     x = self.batchnorm3(x)\n",
    "    #     x = F.dropout(x, 0.25)\n",
    "    #     x = self.pooling3(x)\n",
    "        \n",
    "    #     # FC Layer\n",
    "    #     print(x.shape)\n",
    "    #     x = x.reshape(-1, 4*2*39)\n",
    "    #     print(x.shape)\n",
    "    #     x = F.sigmoid(self.fc1(x))\n",
    "    #     return x\n",
    "\n",
    "model = EEGNet()\n",
    "# model(torch.randn((625,)).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f38e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())#, lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfee6714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossi = []\n",
    "\n",
    "# model.train()\n",
    "# for epoch in tqdm(range(10000)):\n",
    "#     optimizer.zero_grad()\n",
    "#     y_pred = model(train_dataset[0]['window'])\n",
    "\n",
    "#     # if epoch == 0:\n",
    "#     #     print(y_pred)\n",
    "\n",
    "#     loss = criterion(y_pred, train_dataset[0]['labels'])\n",
    "#     lossi.append(loss.item())\n",
    "\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     # if epoch <= 1:\n",
    "#     #     for p in model.parameters():\n",
    "#     #         print(p.grad)\n",
    "    \n",
    "\n",
    "# plt.plot(lossi)\n",
    "\n",
    "# print(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f0852f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "lossi = []\n",
    "vallosses = []\n",
    "vallossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28f184b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1021/5000 [7:40:02<29:52:49, 27.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val_i_batch, val_sample_batched \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_dataloader):\n\u001b[0;32m     26\u001b[0m     val_inputs, val_labels \u001b[38;5;241m=\u001b[39m val_sample_batched[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m'\u001b[39m], val_sample_batched[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     27\u001b[0m     val_pred \u001b[38;5;241m=\u001b[39m model(val_inputs)\n",
      "File \u001b[1;32mc:\\Users\\grant\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\grant\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\grant\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\grant\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataset.py:414\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[_T_co]:\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;66;03m# add batched sampling support when parent dataset supports it.\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m--> 414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\grant\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\grant\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[2], line 56\u001b[0m, in \u001b[0;36mEEGDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     53\u001b[0m sample \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m'\u001b[39m: window, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: labels}\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 56\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "File \u001b[1;32mc:\\Users\\grant\\anaconda3\\envs\\ml\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m, in \u001b[0;36mMinNormalize.__call__\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m     15\u001b[0m window, labels \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwindow\u001b[39m\u001b[38;5;124m'\u001b[39m], sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(window)):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m#print(len(window))\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     window[channel] \u001b[38;5;241m=\u001b[39m window[channel] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m\n\u001b[0;32m     20\u001b[0m     window[channel] \u001b[38;5;241m=\u001b[39m window[channel] \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(window[channel])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "minValLoss = 9999\n",
    "\n",
    "for epoch in tqdm(range(5000)):\n",
    "    for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        inputs, labels = sample_batched['window'], sample_batched['labels']\n",
    "        #print(sample_batched)\n",
    "        #print(inputs.shape, labels.shape)\n",
    "        y_pred = model(inputs)\n",
    "        # print(y_pred)\n",
    "\n",
    "        # if epoch == 0:\n",
    "        #     print(y_pred)\n",
    "        \n",
    "        #print(i)\n",
    "        #print(window_tensors[i])\n",
    "        #print(y_pred, label_tensors[i])\n",
    "        loss = criterion(y_pred, labels)\n",
    "        lossi.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        for val_i_batch, val_sample_batched in enumerate(val_dataloader):\n",
    "            val_inputs, val_labels = val_sample_batched['window'], val_sample_batched['labels']\n",
    "            val_pred = model(val_inputs)\n",
    "            loss = criterion(val_pred, val_labels)\n",
    "            vallossi.append(loss.item())\n",
    "        \n",
    "        # scheduler.step(np.mean(vallossi))\n",
    "        \n",
    "        # if epoch <= 1:\n",
    "        #     for p in model.parameters():\n",
    "        #         print(p.grad)\n",
    "    \n",
    "    losses.append(np.mean(lossi))\n",
    "    avgvalloss = np.mean(vallossi)\n",
    "    if avgvalloss < minValLoss:\n",
    "        minValLoss = avgvalloss\n",
    "        torch.save(model.state_dict(), 'bestvalmodel.pt')\n",
    "    vallosses.append(avgvalloss)\n",
    "    if epoch % 5 == 0:\n",
    "        plt.plot(losses, \"b\")\n",
    "        plt.plot(vallosses, \"g\")\n",
    "        plt.savefig('./valloss.png')\n",
    "        plt.close()\n",
    "    lossi = []\n",
    "    vallossi = []\n",
    "    \n",
    "\n",
    "plt.plot(losses, \"b\")\n",
    "plt.plot(vallosses, \"g\")\n",
    "\n",
    "print(losses)\n",
    "\n",
    "print(losses[-1])\n",
    "torch.save(model.state_dict(), 'finaltrainmodel.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "minindex = torch.argmin(torch.tensor(vallosses))\n",
    "maxindex = torch.argmax(torch.tensor(vallosses))\n",
    "print(losses[minindex], vallosses[minindex])\n",
    "print(vallosses[maxindex], vallosses[maxindex] - vallosses[minindex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147eb4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWeights = torch.load('./bestvalmodel.pt', weights_only=True)\n",
    "#modelWeights = torch.load('./finaltrainmodel.pt', weights_only=True)\n",
    "model = EEGNet()\n",
    "model.load_state_dict(modelWeights)\n",
    "model.eval()\n",
    "truepreds = 0\n",
    "falsepreds = 0\n",
    "truepositives = 0\n",
    "falsepositives = 0\n",
    "truenegatives = 0\n",
    "falsenegatives = 0\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        if i < 3:\n",
    "            print(test_dataset[i]['window'])\n",
    "        y_pred = model(test_dataset[i]['window'])\n",
    "        # print(y_pred, test_dataset[i]['labels'])\n",
    "        pred = (y_pred >= 0.5)\n",
    "        preds.append(pred)\n",
    "        label = test_dataset[i]['labels']\n",
    "        labels.append(label)\n",
    "        if pred == label:\n",
    "            truepreds += 1\n",
    "            if pred == 1:\n",
    "                truepositives += 1\n",
    "            else:\n",
    "                truenegatives += 1\n",
    "        else:\n",
    "            falsepreds += 1\n",
    "            if pred == 1:\n",
    "                falsepositives += 1\n",
    "            else:\n",
    "                falsenegatives += 1\n",
    "\n",
    "print(truepreds / (truepreds + falsepreds))\n",
    "print(truepositives, truenegatives, falsepositives, falsenegatives)\n",
    "\n",
    "f1Score = 2 * truepositives / (2 * truepositives + falsepositives + falsenegatives)\n",
    "print(f1Score)\n",
    "\n",
    "f1ScoreSKL = f1_score(labels, preds)\n",
    "print(f1ScoreSKL)\n",
    "\n",
    "# for x in test_dataset:\n",
    "#     print(x[\"labels\"])\n",
    "\n",
    "print(len(test_dataset))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f46686",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((eeg_dataset[0]['window']))\n",
    "#print(torch.min((no_normalize[0]['window'] - torch.min(no_normalize[0]['window']))/(torch.max(no_normalize[0]['window']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'oct7model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
