{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3505fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from brainflow.data_filter import DataFilter, FilterTypes, DetrendOperations, WindowOperations\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176a201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        window, labels = sample['window'], sample['labels']\n",
    "        return {'window': torch.tensor(window.values).unsqueeze(0).to(torch.float32), \n",
    "                'labels': torch.tensor(labels).to(torch.float32)}#.values)}\n",
    "\n",
    "class AbsoluteValue(object):\n",
    "    def __call__(self, sample):\n",
    "        window, labels = sample['window'], sample['labels']\n",
    "        return {'window': torch.abs(window), \n",
    "                'labels': labels}\n",
    "\n",
    "class Normalize(object):\n",
    "    def __call__(self, sample):\n",
    "        window, labels = sample['window'], sample['labels']\n",
    "        return {'window': F.normalize(window), \n",
    "                'labels': labels}\n",
    "\n",
    "class MinNormalize(object):\n",
    "    def __call__(self, sample):\n",
    "        window, labels = sample['window'], sample['labels']\n",
    "        min = torch.min(window)\n",
    "        window = window - min\n",
    "        window = window / torch.max(window)\n",
    "        return {'window': (window), \n",
    "                'labels': labels}\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.csv_file = pd.read_csv(csv_file, delimiter='\\t', header=None)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # if idx >= len(self.csv_file) / 1250:\n",
    "        #     return\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        window = self.csv_file.iloc[idx*1250:idx*1250+1250, 7]\n",
    "        labels = [self.csv_file.iloc[idx*1250, 32]]#:idx*1250+1250, 32] # remove brackets for timestep prediction\n",
    "        sample = {'window': window, 'labels': labels}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f50ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 21 20\n",
      "33 30\n",
      "10 11\n",
      "9 11\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = EEGDataset(csv_file='./fullData.csv', transform=transforms.Compose([ToTensor(),\n",
    "                                                                                  AbsoluteValue(),\n",
    "                                                                                  MinNormalize()]))\n",
    "\n",
    "kuba_dataset = EEGDataset(csv_file='./data/kuba.csv', transform=transforms.Compose([ToTensor(),\n",
    "                                                                                  AbsoluteValue(),\n",
    "                                                                                  MinNormalize()]))\n",
    "\n",
    "eeg_dataset = torch.utils.data.Subset(eeg_dataset, range(0, 104))\n",
    "kuba_dataset = torch.utils.data.Subset(eeg_dataset, range(0, 48))\n",
    "\n",
    "torch.manual_seed(50) # 80\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(eeg_dataset, [0.6, 0.2, 0.2])\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "\n",
    "zerocount = 0\n",
    "onecount = 0\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    if train_dataset[i]['labels'][0] == 1:\n",
    "        onecount += 1\n",
    "    else:\n",
    "        zerocount += 1\n",
    "\n",
    "print(onecount, zerocount)\n",
    "\n",
    "zerocount = 0\n",
    "onecount = 0\n",
    "\n",
    "for i in range(len(val_dataset)):\n",
    "    if val_dataset[i]['labels'][0] == 1:\n",
    "        onecount += 1\n",
    "    else:\n",
    "        zerocount += 1\n",
    "\n",
    "print(onecount, zerocount)\n",
    "\n",
    "zerocount = 0\n",
    "onecount = 0\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    if test_dataset[i]['labels'][0] == 1:\n",
    "        onecount += 1\n",
    "    else:\n",
    "        zerocount += 1\n",
    "\n",
    "print(onecount, zerocount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bca979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 1, 1250])\n",
      "torch.Size([63, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jy/pdjxhl6d6q58q0b7w0sk_g_80000gn/T/ipykernel_2072/2291086987.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  window_tensors = torch.load('window_tensors.pt')\n",
      "/var/folders/jy/pdjxhl6d6q58q0b7w0sk_g_80000gn/T/ipykernel_2072/2291086987.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  label_tensors = torch.load('label_tensors.pt')\n"
     ]
    }
   ],
   "source": [
    "num_train = len(train_dataset)\n",
    "window_tensors = torch.empty(size=(num_train, 1, 1250))\n",
    "label_tensors = torch.empty(size=(num_train, 1))\n",
    "\n",
    "for i in range(num_train):\n",
    "    window_tensors[i] = train_dataset[i]['window']\n",
    "    label_tensors[i] = train_dataset[i]['labels']\n",
    "\n",
    "torch.save(window_tensors, 'window_tensors.pt')\n",
    "torch.save(label_tensors, 'label_tensors.pt')\n",
    "\n",
    "window_tensors = torch.load('window_tensors.pt')\n",
    "label_tensors = torch.load('label_tensors.pt')\n",
    "\n",
    "print(window_tensors.shape)\n",
    "print(label_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd116314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1, 1250])\n",
      "torch.Size([21, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jy/pdjxhl6d6q58q0b7w0sk_g_80000gn/T/ipykernel_2072/622086804.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_window_tensors = torch.load('val_window_tensors.pt')\n",
      "/var/folders/jy/pdjxhl6d6q58q0b7w0sk_g_80000gn/T/ipykernel_2072/622086804.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_label_tensors = torch.load('val_label_tensors.pt')\n"
     ]
    }
   ],
   "source": [
    "num_val = len(val_dataset)\n",
    "val_window_tensors = torch.empty(size=(num_val, 1, 1250))\n",
    "val_label_tensors = torch.empty(size=(num_val, 1))\n",
    "\n",
    "for i in range(num_val):\n",
    "    val_window_tensors[i] = val_dataset[i]['window']\n",
    "    val_label_tensors[i] = val_dataset[i]['labels']\n",
    "\n",
    "torch.save(val_window_tensors, 'val_window_tensors.pt')\n",
    "torch.save(val_label_tensors, 'val_label_tensors.pt')\n",
    "\n",
    "val_window_tensors = torch.load('val_window_tensors.pt')\n",
    "val_label_tensors = torch.load('val_label_tensors.pt')\n",
    "\n",
    "print(val_window_tensors.shape)\n",
    "print(val_label_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d515da0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Model:\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([3, 128]) from checkpoint, the shape in current model is torch.Size([2, 128]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[1;32m     48\u001b[0m model \u001b[38;5;241m=\u001b[39m Model()\n\u001b[0;32m---> 49\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m80devf1.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39mrequires_grad\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Model:\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([3, 128]) from checkpoint, the shape in current model is torch.Size([2, 128]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "      \n",
    "        self.conv1 = nn.Conv1d(1, 32, 7, padding=3)\n",
    "        self.in1 = nn.InstanceNorm2d(32)  \n",
    "        \n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.in2 = nn.InstanceNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.in3 = nn.InstanceNorm2d(128)\n",
    "        \n",
    "        self.pool = nn.AvgPool1d(3)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(\"Shape check\", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(\"Shape check 2\", x.shape)\n",
    "        x = F.relu(self.in1(x))\n",
    "        print(\"Shape check 3\", x.shape)\n",
    "        #x = F.relu(self.in1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        print(\"Shape check 4\", x.shape)\n",
    "        \n",
    "        x = F.relu(self.in2(self.conv2(x)))\n",
    "        print(\"Shape check 5\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(\"Shape check 6\", x.shape)\n",
    "        \n",
    "        x = F.relu(self.in3(self.conv3(x)))\n",
    "        print(\"Shape check 7\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(\"Shape check 8\", x.shape)\n",
    "        \n",
    "        x = self.global_pool(x)\n",
    "        print(\"Shape check 9\", x.shape)\n",
    "        x = torch.flatten(x, start_dim =1)\n",
    "        print(\"Shape check 10\", x.shape)\n",
    "        test = self.fc(x)\n",
    "        print(\"Final shape\", test.shape)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load('80devf1.pt', weights_only=True, map_location='cpu'))\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee6714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossi = []\n",
    "\n",
    "# model.train()\n",
    "# for epoch in tqdm(range(10000)):\n",
    "#     optimizer.zero_grad()\n",
    "#     y_pred = model(train_dataset[0]['window'])\n",
    "\n",
    "#     # if epoch == 0:\n",
    "#     #     print(y_pred)\n",
    "\n",
    "#     loss = criterion(y_pred, train_dataset[0]['labels'])\n",
    "#     lossi.append(loss.item())\n",
    "\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     # if epoch <= 1:\n",
    "#     #     for p in model.parameters():\n",
    "#     #         print(p.grad)\n",
    "    \n",
    "\n",
    "# plt.plot(lossi)\n",
    "\n",
    "# print(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0852f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "lossi = []\n",
    "vallosses = []\n",
    "vallossi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 5 5\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, drop_last=True, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, drop_last=True, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, drop_last=True, shuffle=False, num_workers=0)\n",
    "#test_dataloader = DataLoader(eeg_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "print(len(train_dataloader), len(val_dataloader), len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18565c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/instancenorm.py:115: UserWarning: input's size at dim=0 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape check torch.Size([4, 1, 1250])\n",
      "Shape check 2 torch.Size([4, 32, 1250])\n",
      "Shape check 3 torch.Size([4, 32, 1250])\n",
      "Shape check 4 torch.Size([4, 32, 416])\n",
      "Shape check 5 torch.Size([4, 64, 416])\n",
      "Shape check 6 torch.Size([4, 64, 138])\n",
      "Shape check 7 torch.Size([4, 128, 138])\n",
      "Shape check 8 torch.Size([4, 128, 46])\n",
      "Shape check 9 torch.Size([4, 128, 1])\n",
      "Shape check 10 torch.Size([4, 128])\n",
      "Final shape torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4, 3])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(y_pred)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# if epoch == 0:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     print(y_pred)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m lossi\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/functional.py:3545\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3543\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3546\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3547\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3548\u001b[0m     )\n\u001b[1;32m   3550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4, 3])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "minValLoss = 9999\n",
    "\n",
    "for epoch in tqdm(range(1)):\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        # print(window_tensors[i].shape)\n",
    "        inputs = data['window']\n",
    "        labels = data['labels']\n",
    "        y_pred = model(inputs)\n",
    "        # print(y_pred)\n",
    "\n",
    "        # if epoch == 0:\n",
    "        #     print(y_pred)\n",
    "\n",
    "        loss = criterion(y_pred, labels)\n",
    "        lossi.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        for j, valdata in enumerate(val_dataloader):\n",
    "            valinputs = valdata['window']\n",
    "            vallabels = valdata['labels']\n",
    "            val_pred = model(valinputs)\n",
    "            loss = criterion(val_pred, vallabels)\n",
    "            vallossi.append(loss.item())\n",
    "        \n",
    "        # if epoch <= 1:\n",
    "        #     for p in model.parameters():\n",
    "        #         print(p.grad)\n",
    "    \n",
    "    losses.append(np.mean(lossi))\n",
    "    avgvalloss = np.mean(vallossi)\n",
    "    if avgvalloss < minValLoss:\n",
    "        minValLoss = avgvalloss\n",
    "        torch.save(model.state_dict(), 'bestvalmodel.pt')\n",
    "    vallosses.append(avgvalloss)\n",
    "    if epoch % 100 == 0:\n",
    "        plt.plot(losses, \"b\")\n",
    "        plt.plot(vallosses, \"g\")\n",
    "        plt.savefig('./valloss.png')\n",
    "        plt.close()\n",
    "    lossi = []\n",
    "    vallossi = []\n",
    "    \n",
    "\n",
    "plt.plot(losses, \"b\")\n",
    "plt.plot(vallosses, \"g\")\n",
    "\n",
    "print(losses)\n",
    "\n",
    "print(losses[-1])\n",
    "torch.save(model.state_dict(), 'finaltrainmodel.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f184b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1250])\n",
      "Shape check torch.Size([1, 1250])\n",
      "Shape check 2 torch.Size([32, 1250])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected 3D or 4D input (got 2D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(window_tensors[i]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_tensors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(y_pred)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# if epoch == 0:\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#     print(y_pred)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, label_tensors[i])\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[25], line 24\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape check 2\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 24\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape check 3\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#x = F.relu(self.in1(self.conv1(x)))\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/instancenorm.py:105\u001b[0m, in \u001b[0;36m_InstanceNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     feature_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_no_batch_dim()\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(feature_dim) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/instancenorm.py:317\u001b[0m, in \u001b[0;36mInstanceNorm2d._check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_input_dim\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected 3D or 4D input (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: expected 3D or 4D input (got 2D input)"
     ]
    }
   ],
   "source": [
    "# minValLoss = 9999\n",
    "\n",
    "# for epoch in tqdm(range(1)):\n",
    "#     for i in range(len(window_tensors)):\n",
    "#         optimizer.zero_grad()\n",
    "#         model.train()\n",
    "#         print(window_tensors[i].shape)\n",
    "#         y_pred = model(window_tensors[i])\n",
    "#         # print(y_pred)\n",
    "\n",
    "#         # if epoch == 0:\n",
    "#         #     print(y_pred)\n",
    "\n",
    "#         loss = criterion(y_pred, label_tensors[i])\n",
    "#         lossi.append(loss.item())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         model.eval()\n",
    "#         for i in range(len(val_window_tensors)):\n",
    "#             val_pred = model(val_window_tensors[i])\n",
    "#             loss = criterion(val_pred, val_label_tensors[i])\n",
    "#             vallossi.append(loss.item())\n",
    "        \n",
    "#         # if epoch <= 1:\n",
    "#         #     for p in model.parameters():\n",
    "#         #         print(p.grad)\n",
    "    \n",
    "#     losses.append(np.mean(lossi))\n",
    "#     avgvalloss = np.mean(vallossi)\n",
    "#     if avgvalloss < minValLoss:\n",
    "#         minValLoss = avgvalloss\n",
    "#         torch.save(model.state_dict(), 'bestvalmodel.pt')\n",
    "#     vallosses.append(avgvalloss)\n",
    "#     if epoch % 100 == 0:\n",
    "#         plt.plot(losses, \"b\")\n",
    "#         plt.plot(vallosses, \"g\")\n",
    "#         plt.savefig('./valloss.png')\n",
    "#         plt.close()\n",
    "#     lossi = []\n",
    "#     vallossi = []\n",
    "    \n",
    "\n",
    "# plt.plot(losses, \"b\")\n",
    "# plt.plot(vallosses, \"g\")\n",
    "\n",
    "# print(losses)\n",
    "\n",
    "# print(losses[-1])\n",
    "# torch.save(model.state_dict(), 'finaltrainmodel.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82ac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5267679425518191 0.42550390597520144\n"
     ]
    }
   ],
   "source": [
    "minindex = torch.argmin(torch.tensor(vallosses))\n",
    "print(losses[minindex], vallosses[minindex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab49050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7357, 0.4009, 0.7700,  ..., 0.4009, 0.0419, 0.3947]])\n",
      "tensor([[0.8350, 0.5764, 0.7985,  ..., 0.0136, 0.2617, 0.0000]])\n",
      "tensor([[0.5309, 0.7825, 0.4786,  ..., 0.1769, 0.3101, 0.2576]])\n",
      "0.85\n",
      "9 8 3 0\n",
      "0.8571428571428571\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "modelWeights = torch.load('./bestvalmodel.pt', weights_only=True)\n",
    "#modelWeights = torch.load('./finaltrainmodel.pt', weights_only=True)\n",
    "model = EEGEyesOpenCloseClassifier()\n",
    "model.load_state_dict(modelWeights)\n",
    "model.eval()\n",
    "truepreds = 0\n",
    "falsepreds = 0\n",
    "truepositives = 0\n",
    "falsepositives = 0\n",
    "truenegatives = 0\n",
    "falsenegatives = 0\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        if i < 3:\n",
    "            print(test_dataset[i]['window'])\n",
    "        y_pred = model(test_dataset[i]['window'])\n",
    "        # print(y_pred, test_dataset[i]['labels'])\n",
    "        pred = (y_pred >= 0.5)\n",
    "        preds.append(pred)\n",
    "        label = test_dataset[i]['labels']\n",
    "        labels.append(label)\n",
    "        if pred == label:\n",
    "            truepreds += 1\n",
    "            if pred == 1:\n",
    "                truepositives += 1\n",
    "            else:\n",
    "                truenegatives += 1\n",
    "        else:\n",
    "            falsepreds += 1\n",
    "            if pred == 1:\n",
    "                falsepositives += 1\n",
    "            else:\n",
    "                falsenegatives += 1\n",
    "\n",
    "print(truepreds / (truepreds + falsepreds))\n",
    "print(truepositives, truenegatives, falsepositives, falsenegatives)\n",
    "\n",
    "f1Score = 2 * truepositives / (2 * truepositives + falsepositives + falsenegatives)\n",
    "print(f1Score)\n",
    "\n",
    "f1ScoreSKL = f1_score(labels, preds)\n",
    "print(f1ScoreSKL)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f46686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7548, 0.5327, 0.8003,  ..., 0.4127, 0.7042, 0.4506]])\n"
     ]
    }
   ],
   "source": [
    "print((eeg_dataset[0]['window']))\n",
    "#print(torch.min((no_normalize[0]['window'] - torch.min(no_normalize[0]['window']))/(torch.max(no_normalize[0]['window']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'oct7model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
